{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98625d7e-d445-447b-a023-1165e85c2662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download concluído!\n"
     ]
    }
   ],
   "source": [
    "#em vez do wget do video, utilizei esta forma para importar o texto, de uma maneira mais pratica\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()  # Lê todo o conteúdo do arquivo\n",
    "\n",
    "print(\"Download concluído!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070aeb18-4356-419e-ad3a-16a6f755f132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text)) #qtd de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6ba203-d534-4246-afd8-86e2b460ff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000]) #1000 primeiros caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3038f46-5185-401b-8a48-5d151b55b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text))) # contem todos os caracteres únicos do texto(set), organizados em uma lista ordenada\n",
    "vocab_size = len(chars) #recebe a qtd de caracteres unicos\n",
    "print(\"\".join(chars)) #junta os caracteres em uma unica string\n",
    "print(vocab_size) #imprime a qtd caracteres unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3390613-d24d-443b-86b3-d4b33ff93cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "#basicamente, o encode pega uma string e transoforma em numeros inteiros e o decode realiza o contrario, transforma\n",
    "#numeors inteiros em strings\n",
    "\n",
    "stoi = { ch:i for i,ch in enumerate(chars)} #mapeia cada caractere unico em um indice\n",
    "itos = { i:ch for i,ch in enumerate(chars)} #mapeia cada indice para um caractere unico\n",
    "encode = lambda s: [stoi[c] for c in s] #recebe um caractere e converte para o seu respectivo indice\n",
    "decode = lambda l: \"\".join([itos[i] for i in l]) #recebe um indice e convercete para o seu respectivo caractere\n",
    "\n",
    "print(encode(\"hii there\")) #apenas imprime os indices do caracteres anteriormente mapeados\n",
    "print(decode(encode(\"hii there\"))) #imprime os caracteres dos indices anteriormente mapeados   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "903e9d06-3f2e-4977-899a-566d6cbab9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "#ira codificar os 1000 caracteres para indices\n",
    "\n",
    "import torch  \n",
    "data = torch.tensor(encode(text), dtype =torch.long) #ira guardar na variavel um tensor PyTorch a partir da lista de índices\n",
    "print(data.shape, data.dtype) #imprimir o shape e o tipo dos indices\n",
    "print(data[:1000]) #imprimir os 1000 caracteres traduzidos para indices respecitivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744208fd-9975-4a06-b6bc-1b26082fd42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int (0.9*len(data)) #pega o 90% de data (visto no bloco anterior)\n",
    "train_data = data[:n] #utiliza estes 90% para treinammento\n",
    "val_data = data[n:] #utiliza o resto para validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdea4a3e-2fb6-4416-8348-9fb8bce2d83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 #cada bloco de dados tera 8 elementos\n",
    "train_data[:block_size+1] #os dados de treinamento ira receber 8 + 1, ou seja, 9 elementos, utilizado para \"previsao\" de um dado posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62c7110-d851-4f61-aa36-587d3ef95c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quando a entrada ser tensor([18]) o alvo: 47\n",
      "quando a entrada ser tensor([18, 47]) o alvo: 56\n",
      "quando a entrada ser tensor([18, 47, 56]) o alvo: 57\n",
      "quando a entrada ser tensor([18, 47, 56, 57]) o alvo: 58\n",
      "quando a entrada ser tensor([18, 47, 56, 57, 58]) o alvo: 1\n",
      "quando a entrada ser tensor([18, 47, 56, 57, 58,  1]) o alvo: 15\n",
      "quando a entrada ser tensor([18, 47, 56, 57, 58,  1, 15]) o alvo: 47\n",
      "quando a entrada ser tensor([18, 47, 56, 57, 58,  1, 15, 47]) o alvo: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size] #seleciona os 8 primeiros elementos\n",
    "y = train_data[1:block_size+1] #seleciona os seguintes 8 elementos (bloco a ser previsto a partir da entrada)\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1] #percorre o bloco de codigo ate o seu ultimo, adcionando um dado a cada iteracao\n",
    "    target = y[t] # proximo caractere a ser previsto apos o contexto.\n",
    "    print(f\"quando a entrada ser {context} o alvo: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd46a9d-fa51-4c1f-99a2-566b9c07c745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is [24] the target: 43\n",
      "when input is [24, 43] the target: 58\n",
      "when input is [24, 43, 58] the target: 5\n",
      "when input is [24, 43, 58, 5] the target: 57\n",
      "when input is [24, 43, 58, 5, 57] the target: 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
      "when input is [44] the target: 53\n",
      "when input is [44, 53] the target: 56\n",
      "when input is [44, 53, 56] the target: 1\n",
      "when input is [44, 53, 56, 1] the target: 58\n",
      "when input is [44, 53, 56, 1, 58] the target: 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52] the target: 58\n",
      "when input is [52, 58] the target: 1\n",
      "when input is [52, 58, 1] the target: 58\n",
      "when input is [52, 58, 1, 58] the target: 46\n",
      "when input is [52, 58, 1, 58, 46] the target: 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
      "when input is [25] the target: 17\n",
      "when input is [25, 17] the target: 27\n",
      "when input is [25, 17, 27] the target: 10\n",
      "when input is [25, 17, 27, 10] the target: 0\n",
      "when input is [25, 17, 27, 10, 0] the target: 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337) #define a semente para o gerador de numeros aleatorios\n",
    "batch_size = 4 # sequencias independentes que serao executadas paralelamentes\n",
    "block_size = 8 # numero maximo para cada bloco do contexto para previsoes\n",
    "\n",
    "def get_batch(split): \n",
    "    #caso o split for train, usamos os dados de treinamento, caso contrario, usamos os dados de valicao\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    #gera 4 indices aleatorios dentro do intervalo de len(data) - block_size (o que garente que seja divisivel por block_size)\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) \n",
    "    #responsavel por pegar e empilhar varias subsequencias com um intervalo do block_size, que neste caso e 8\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    #o y pegar e empilhar o subsequente de x, ou seja, os proximos caracteres apos cada subsequencia de x\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train') # volta os dados de entrada e saida para o conjunto train\n",
    "print('inputs:')\n",
    "print(xb.shape) #[batch_size, block_size]\n",
    "print(xb) #conteudo das entradas (subsequencias anteriores)\n",
    "print('targets:')\n",
    "print(yb.shape) #[batch_size, block_size]\n",
    "print(yb) #conteudo dos alvos (proximos caracteres apos a subsequencia de xb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "#preve o proximo caractere pelo contexto crescente anterior, ou seja, para cada \"conjunto\", \n",
    "#o modelo tentara prever qual sera o proximo, com o context crescendo, enquanto o target(alvo), sera o proximo numero\n",
    "for b in range(batch_size): \n",
    "    for t in range(block_size): \n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8c9a180-f136-485c-8657-73767eacb44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) #imprime o transformador (dado de entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b9488f5-d248-4044-94bf-d05610ca3bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        #cria uma tabela com os embedding(numeros representando palavras), para mapear uma distribuicoes de logits\n",
    "        #assim conseguindo a previsao de porcentagem de palavras poderia completar a frase\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    #responsavel pelo processamento da entrada e pela geracao da saida do modelo.\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # o indice e passado pela camada de embeddings, retornando um logits para cada token de sequencia\n",
    "        logits = self.token_embedding_table(idx) # gera tensor logits(B(batch_size),T(tamanho da sequencia),C(vocab_size))\n",
    "\n",
    "        if targets is None: #caso nao tenha palavras corretas para comparar, apenas continua\n",
    "            loss = None\n",
    "        else:\n",
    "            # \"achatamos\" o shape, multipliando o B e T para, o resultado sendo o total de previsoes e o C representando as possibilidades\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)\n",
    "            #usando a cross_entrpoty para saber o quao errada sao as previsoes, comparadando com as palavras corretas(targets)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    # idx e o (B, T) array(sequencia inicial das palavras), e o maximo de tokens que o modelo deve gerar\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "            for _ in range(max_new_tokens):\n",
    "                # faz uma previsao baseada no texto atual, retornando logits\n",
    "                logits, loss = self(idx)\n",
    "                # pega a ultima palavra do contexto para prever a proxima, ignorando as anteriores\n",
    "                logits = logits[:, -1, :] # becomes (B, C)\n",
    "                # aplica o softmax para transformas cada probabildiade dos logits em porcentagem entre 0 e 1\n",
    "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "                # escolha um logit aleatorio (quanto maior porcentagem, mais chance de ser escolhida)\n",
    "                idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "                # adciona no final da sequencia, assim o modelo tera um contexto melhor para a proxima rodada\n",
    "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "            return idx #retorna a sequencia completa\n",
    "\n",
    "m = BigramLanguageModel(vocab_size) #criacao de um modelo m\n",
    "logits, loss = m(xb, yb) #chamando o modelo para treinar/testar\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "#comeca com o texto no indice 0 e gera 100 novas palavras, e o decode transforma os numeros em texto novamente\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "175093f7-eac7-4691-9048-730af5d4f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um otimizacor para o modelo m, onde a taxa de aprendizado e lr=1e-3(aproximadamente 0.001)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef903a9a-7570-4d4b-b776-884685cbe190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5727508068084717\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000): # o treinamento ira ocorrer em 100 epocas\n",
    "\n",
    "    # pegar um conjutno de exemplos na base de dados de train, retornando uma matriz, no caso o xb(entrada), yb(target)\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # calcula os logits e a funcao de perda(loss), mostrando o quao errado esta a previsao\n",
    "    logits, loss = m(xb, yb)\n",
    "    #zera os gradientes anteriores a fim de evitar possiveis conflitos\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    # mostra o quao errado o modelo estava em relacao a previsao, com este feedback, conseguimos ajustar os parametros\n",
    "    loss.backward()\n",
    "    #com base no resultado anterior, aplica os ajustes nos pesos\n",
    "    optimizer.step()\n",
    "\n",
    "#imprime o valor de perda final\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67efa908-f7ab-4aa0-9e2c-0bc6c78169ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iyoteng h hasbe pave pirance\n",
      "Rie hicomyonthar's\n",
      "Plinseard ith henoure wounonthioneir thondy, y heltieiengerofo'dsssit ey\n",
      "KIN d pe wither vouprrouthercc.\n",
      "hathe; d!\n",
      "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n",
      "h hay.JUCle n prids, r loncave w hollular s O:\n",
      "HIs; ht anjx?\n",
      "\n",
      "DUThinqunt.\n",
      "\n",
      "LaZAnde.\n",
      "athave l.\n",
      "KEONH:\n",
      "ARThanco be y,-hedarwnoddy scace, tridesar, wnl'shenous s ls, theresseys\n",
      "PlorseelapinghiybHen yof GLUCEN t l-t E:\n",
      "I hisgothers je are!-e!\n",
      "QLYotouciullle'z\n"
     ]
    }
   ],
   "source": [
    "#comecando com uma sequencia de comprimento 1 (um único token) para 1 exemplo de batch, ferando 500 novos tokens\n",
    "#converte para uma lista, e o encode transforma em frase\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0488461c-26e4-4ee4-9350-ed6b06598093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3)) #matriz de pesos normalizados\n",
    "a = a / torch.sum(a, 1, keepdim=True) \n",
    "b = torch.randint(0,10,(3,2)).float() #valores a serem agradados\n",
    "c = a @ b #realiza a multiplicacao de matrizes, onde cada linha de c e uma media ponderada das linhas de b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4f72711-1b92-4da0-b097-dfe604171afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels, ou seja, tridimensional, fixando para o numeros sempre serem os mesmo\n",
    "x = torch.randn(B,T,C) #define os tamanho de btc\n",
    "x.shape #numeros aleatorios normais com media 0, desvio padrao 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40ef1f78-265b-425f-afde-f5b75f08ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i], usando for que nao seria a maneira mais eficiente\n",
    "xbow = torch.zeros((B,T,C)) #cria um tensor cheio de zeros\n",
    "for b in range(B): #percorre as frases\n",
    "    for t in range(T): #percorre todas as palavras dentro da frase \n",
    "        xprev = x[b,:t+1] # (t,C) contem todas as palavras anteriores e a atual ate o tempo t\n",
    "        xbow[b,t] = torch.mean(xprev, 0) #calcula a media das polavras anteriores e substitui a palavra atual por essa media calculada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6838eea-5cc9-4e0c-a27b-902267d7fe2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] #os 8 elementos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0acf4c0c-3b5d-4a91-9eb4-7dc1ffdf4aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0] #os elementos agora calculado com a sua media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "323e35bd-ab41-4e9e-b1da-a58c21961e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vmultiplicacao de matrizes, realizando a media acumulada de uma forma mais eficiente\n",
    "wei = torch.tril(torch.ones(T, T)) #cria uma matriz triangular inferior preenchidos com 1, e o triangular supeior com 0\n",
    "wei = wei / wei.sum(1, keepdim=True) #cada linha de 1 vai ser normalizada\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C) #para cada tempo, pegar os valores anteriores em x e multiplciar pela matriz wei\n",
    "torch.allclose(xbow, xbow2) #verifica se o calculo realizado agora e o com looping sao quase identicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7707121-662b-4476-b76d-67645f099414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bef7727-72c9-4562-83c6-7bc45cfa6047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2363e-08)\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(torch.abs(xbow - xbow2)))  #a diferenca nao e tao grande de um para o outro, sendo praticamente 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "546e2012-fce0-44b0-a210-9b88665fc2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: usando softmax\n",
    "tril = torch.tril(torch.ones(T, T)) #cria a mesma matriz triangular inferiores com 1\n",
    "wei = torch.zeros((T,T)) #matriz wei cheia de 0\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) #substitue os valores da diagonal para cima(os zeros), e substitui por -inf, fazendo o softmax ignorar\n",
    "wei = F.softmax(wei, dim=-1) #aplica o softmax na ultima dimensao, convertendo os valores em probabildiades\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c99dd74d-6d0a-4de5-adcd-2e036f7be113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: faz com que tenha um mecanismo, fazendo com que cada palavra fique de olho nas palavras anteriores\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # BTC\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False) #representa a identidade de cada palavra\n",
    "query = nn.Linear(C, head_size, bias=False) #representa o q esta sendo procurado em outras palavras\n",
    "value = nn.Linear(C, head_size, bias=False) #representa as informacoes a serem usadas na saida\n",
    "k = key(x)   # (B, T, 16) #chave das palavras, diminuindo a dimensionalidade para 16, tornaod a computacao mais eficiente\n",
    "q = query(x) # (B, T, 16) #consulta das palavras\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T), ficando (4,8,8), armazenando o quanto cada palavra deve prestar atencao nas outras\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T)) #matriz triangular inferior\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) #substitui os valores a cima da diagonal por -inf, bloqueando o futuro\n",
    "wei = F.softmax(wei, dim=-1) #softmax, probabilidade entre 0 e 1\n",
    "\n",
    "v = value(x) #transforma os valores de x em valores v, com forma (B,T,16)\n",
    "out = wei @ v #multiplixa os pesos da atencao(wei) pelos valores\n",
    "#out = wei @ x, onde cada palavra tem as informacoes mais relevantes de cada palavra anterior\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8ee9f2a-a2b5-432c-a6c8-40759d0525d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21e5136c-657d-4448-9943-5d3c14931063",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size) #matriz de chaves\n",
    "q = torch.randn(B,T,head_size) #matriz de consultas\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5 #calculo das matriz,gerando um mapa onde cada linha representa o quanto uma palavra tem a ver com a outra\n",
    "#e depois e aplicado um scaling, para normalizar os valores e evitar numeros mto grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd689846-6510-42be-abf9-373f4a9d9716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var() #variancia dos elementos de k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff5b0491-bb89-43d3-8f72-afbc33859d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var() #calcular a variancia dos elementos de q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf8b0c04-8b9a-4f78-aa06-f8b0a16b1e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var() #calcular a variancia dos elementos de wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb6eced3-b5b0-4d31-8309-5c6ef6e89b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1) # probabilidade de cada numero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6412459-1b86-4fec-946d-b2d38208af6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # multipliocando por 8, o maior valor fica muito maior que o restante\n",
    "#assim, se aproxima de uma distribuicao one-hot, quase toda probabilidade vai para o valor mais alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "095ceab1-7b3b-463e-8b70-b10a2e1269e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # camada de normalziacao, serve para ajustar os dados\n",
    "\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1): \n",
    "    self.eps = eps #salvando o valor de eps\n",
    "    self.gamma = torch.ones(dim) #tensor gamma com o tamanho de dim preenchido por 1, usado para ajustar amplitude\n",
    "    self.beta = torch.zeros(dim) #tensor beta com o tamanho de dim, usado para ajustar deslocamento\n",
    "\n",
    "  def __call__(self, x): #onde a normalizacao ocorrera\n",
    "    xmean = x.mean(1, keepdim=True) # calcula a media de cada linha dos dados, e a media ao longo das colunas de cada linha\n",
    "    xvar = x.var(1, keepdim=True) #caclula a variancia de cada linha dos dados, e a variancia ao longo das colunas de cada linha\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normaliza os dados, para a media ficar 0 e a variancia 1\n",
    "    self.out = self.gamma * xhat + self.beta #aplicando os ajustes de escala (gamma) e deslocamento(beta) nos dados normalizados\n",
    "    return self.out #valor normlizado ajustado\n",
    "\n",
    "  def parameters(self): #usado para obter os parametros da camada, usados para ajustar os dados, como anteriormente explciados\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100) #100 caracteristeicas para normalizar, pq a entrada tem 100 dimensoes\n",
    "x = torch.randn(32, 100) # 32 exemplos e cada exemplo tem 100 caracteristicas, com numeros aleatorios\n",
    "x = module(x) #passando os dados de x para module\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "462f13c5-5d1a-4365-9c0a-010111e4c857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # calcula a media e o desvio padrao dos 32 valres da primerira caracteristicas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfc19162-8a4f-4050-95a3-d4649ab0ff44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() #calcula a media e o desvio padrao dos 100 valores do primeiro exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "230ee437-8750-492c-bdea-61c42fe45b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209729 M parameters\n",
      "step 0: train loss 4.4116, val loss 4.4022\n",
      "step 100: train loss 2.6568, val loss 2.6670\n",
      "step 200: train loss 2.5091, val loss 2.5058\n",
      "step 300: train loss 2.4195, val loss 2.4335\n",
      "step 400: train loss 2.3507, val loss 2.3569\n",
      "step 500: train loss 2.2964, val loss 2.3128\n",
      "step 600: train loss 2.2407, val loss 2.2499\n",
      "step 700: train loss 2.2055, val loss 2.2191\n",
      "step 800: train loss 2.1640, val loss 2.1870\n",
      "step 900: train loss 2.1240, val loss 2.1503\n",
      "step 1000: train loss 2.1022, val loss 2.1294\n",
      "step 1100: train loss 2.0695, val loss 2.1179\n",
      "step 1200: train loss 2.0379, val loss 2.0796\n",
      "step 1300: train loss 2.0247, val loss 2.0643\n",
      "step 1400: train loss 1.9931, val loss 2.0374\n",
      "step 1500: train loss 1.9707, val loss 2.0302\n",
      "step 1600: train loss 1.9617, val loss 2.0471\n",
      "step 1700: train loss 1.9414, val loss 2.0149\n",
      "step 1800: train loss 1.9082, val loss 1.9963\n",
      "step 1900: train loss 1.9080, val loss 1.9873\n",
      "step 2000: train loss 1.8844, val loss 1.9958\n",
      "step 2100: train loss 1.8716, val loss 1.9787\n",
      "step 2200: train loss 1.8579, val loss 1.9614\n",
      "step 2300: train loss 1.8561, val loss 1.9525\n",
      "step 2400: train loss 1.8412, val loss 1.9427\n",
      "step 2500: train loss 1.8158, val loss 1.9455\n",
      "step 2600: train loss 1.8254, val loss 1.9399\n",
      "step 2700: train loss 1.8114, val loss 1.9334\n",
      "step 2800: train loss 1.8030, val loss 1.9216\n",
      "step 2900: train loss 1.8055, val loss 1.9338\n",
      "step 3000: train loss 1.7935, val loss 1.9192\n",
      "step 3100: train loss 1.7677, val loss 1.9153\n",
      "step 3200: train loss 1.7512, val loss 1.9083\n",
      "step 3300: train loss 1.7560, val loss 1.9064\n",
      "step 3400: train loss 1.7556, val loss 1.8992\n",
      "step 3500: train loss 1.7357, val loss 1.8945\n",
      "step 3600: train loss 1.7230, val loss 1.8897\n",
      "step 3700: train loss 1.7272, val loss 1.8807\n",
      "step 3800: train loss 1.7177, val loss 1.8916\n",
      "step 3900: train loss 1.7225, val loss 1.8732\n",
      "step 4000: train loss 1.7145, val loss 1.8625\n",
      "step 4100: train loss 1.7089, val loss 1.8704\n",
      "step 4200: train loss 1.7029, val loss 1.8632\n",
      "step 4300: train loss 1.6988, val loss 1.8432\n",
      "step 4400: train loss 1.7046, val loss 1.8611\n",
      "step 4500: train loss 1.6891, val loss 1.8490\n",
      "step 4600: train loss 1.6852, val loss 1.8323\n",
      "step 4700: train loss 1.6816, val loss 1.8427\n",
      "step 4800: train loss 1.6630, val loss 1.8398\n",
      "step 4900: train loss 1.6674, val loss 1.8371\n",
      "step 4999: train loss 1.6632, val loss 1.8293\n",
      "\n",
      "ROMEO:\n",
      "But you fret, he I wish his migute:\n",
      "They now I uDWARD IS TIVER:\n",
      "God I camil: and Gen\n",
      "The sitens, and say-wretor upwor alond, liege to makes.\n",
      "Ie plant, sure here than steed thus micks.\n",
      "\n",
      "ANCBY:\n",
      "Prown thomough, go:\n",
      "Eve misiter warges shall it Comme thense noble,\n",
      "I his his poperved quightle:-henger,\n",
      "By the beens us\n",
      "By thou sovours, I sidfut bace pild.\n",
      "\n",
      "KING RICHARD II:\n",
      "Why, by, brother, that let mittuty\n",
      "As this fold naye with windre? He wear the comfort, whom thou strave worge mad him the and enirs, tomght Most accare\n",
      "Haze trues forswelf, simurs of some passes us.\n",
      "\n",
      "BUCKINGHABER:\n",
      "Mewele is some to and pitate head which\n",
      "Hent them it you brote: marry whose\n",
      "Now that the king\n",
      "Where I was us beliess the pair, off withrown lets,\n",
      "Thou bust allanked where rive Afford up doge,\n",
      "Withal I mote imment Wear must,\n",
      "While umonspet the gafieds I'll that confetives:\n",
      "To, no at and her long well.\n",
      "\n",
      "FRORIOLANUS:\n",
      "Mister.\n",
      "\n",
      "MOMINIUS:\n",
      "Ibreath,\n",
      "You away name foons, stravoing, now?\n",
      "We be seemmer with\n",
      "That thou brothels to.\n",
      "Bently, weinsuil on on that the would prevfect,\n",
      "I ward than war\n",
      "of warrant, I us only adgrians viles.\n",
      "\n",
      "PUARDINA:\n",
      "Swell you have stropproad! Lord,\n",
      "Whithin my worsomes: thou make whom undyliers volipper-lady\n",
      "Comany; I his cransmare own heave itson; the thou to?\n",
      "\n",
      "Sove in thus my noman:\n",
      "Mowise if these been.\n",
      "Made, I coutnny and, our how,\n",
      "And sendul, I'll Rambed to deast we miety this dudget I\n",
      "surnmon's Rombordelay's, I and by yonget\n",
      "Than are will the eselpince,---\n",
      "Melpier her tonder'd forth if took.\n",
      "Tuchmed you are flam if then be.----\n",
      "And Git, mustick for\n",
      "The worstery of the, and per none.\n",
      "Dou from with I that: this prequriant that brird\n",
      "ot say mover a detry, I which o' an the;\n",
      "Our since\n",
      "For it Fortunue thus us puilt with requmpt I upor make\n",
      "Here figh unteed that wife then,\n",
      "Thus whicowints toughmed of it fall more.\n",
      "\n",
      "PRISET:\n",
      "Antway, whith these that his revant.\n",
      "Plafe me, thone sure make God it\n",
      "wey maintiny leams the such, heave prant who' you that thy\n",
      "Conguely that withour fatt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hiperparametros\n",
    "batch_size = 16 # quantas sequencias independentes serao processadas em paralelo?\n",
    "block_size = 32 # qual o comprimento maximo do contexto para previsoes?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# baixar o arquivo de texto\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# aqui estao todos os caracteres unicos que ocorrem neste texto\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# criar um mapeamento de caracteres para inteiros\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # codificador: recebe uma string e retorna uma lista de inteiros\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decodificador: recebe uma lista de inteiros e retorna uma string\n",
    "\n",
    "# dividir em conjunto de treino e validacao\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # primeiros 90% serao treino, o resto validacao\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# carregamento de dados\n",
    "def get_batch(split):\n",
    "    # gerar um pequeno lote de dados de entradas x e alvos y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" uma cabeca de autoatencao \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # calcular os pesos de atencao\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # realizar a agregacao ponderada dos valores\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" varias cabecas de autoatencao em paralelo \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" uma camada linear simples seguida de uma nao linearidade \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" bloco do transformer: comunicacao seguida de computacao \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: dimensao do embedding, n_head: numero de cabecas de atencao\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# modelo bigrama super simples\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # cada token acessa diretamente os logits do proximo token a partir de uma tabela de busca\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # camada final de normalizacao\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx e targets sao ambos tensores (B,T) de inteiros\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx e um array (B, T) de indices no contexto atual\n",
    "        for _ in range(max_new_tokens):\n",
    "            # recorta idx para os ultimos block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # obtem as previsoes\n",
    "            logits, loss = self(idx_cond)\n",
    "            # foca apenas no ultimo passo de tempo\n",
    "            logits = logits[:, -1, :] # fica (B, C)\n",
    "            # aplica softmax para obter probabilidades\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # amostra da distribuicao\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # adiciona o indice amostrado a sequencia\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# imprime o numero de parametros do modelo\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parametros')\n",
    "\n",
    "# cria um otimizador do pytorch\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # de tempos em tempos avalia a perda nos conjuntos de treino e validacao\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # amostra um lote de dados\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # avalia a perda\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# gera texto a partir do modelo\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d88b9-af2c-469e-b23f-06e7839a2d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9abbfc-6257-4624-8059-13829b38eed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
